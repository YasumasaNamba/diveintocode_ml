{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】コードの書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】学習・推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/tgs-salt-identification-challenge/train.csv')\n",
    "test = pd.read_csv('input/tgs-salt-identification-challenge/sample_submission.csv')\n",
    "depth = pd.read_csv('input/tgs-salt-identification-challenge/depths.csv')\n",
    "\n",
    "train_src = 'input/tgs-salt-identification-challenge/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('input/tgs-salt-identification-challenge/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('input/tgs-salt-identification-challenge/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a4b0afc50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle_mask</th>\n",
       "      <th>z</th>\n",
       "      <th>coverage</th>\n",
       "      <th>coverage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>575d24d81d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a266a2a9df</td>\n",
       "      <td>5051 5151</td>\n",
       "      <td>794</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75efad62c1</td>\n",
       "      <td>9 93 109 94 210 94 310 95 411 95 511 96 612 96...</td>\n",
       "      <td>468</td>\n",
       "      <td>0.993334</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34e51dba6a</td>\n",
       "      <td>48 54 149 54 251 53 353 52 455 51 557 50 659 4...</td>\n",
       "      <td>727</td>\n",
       "      <td>0.149201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4875705fb0</td>\n",
       "      <td>1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...</td>\n",
       "      <td>797</td>\n",
       "      <td>0.042839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>9cbd5ddba4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>caa039b231</td>\n",
       "      <td>2398 7 2499 11 2600 16 2700 22 2801 26 2901 29...</td>\n",
       "      <td>602</td>\n",
       "      <td>0.376924</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1306fcee4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>48d81e93d9</td>\n",
       "      <td>2828 1 2927 3 3026 5 3126 6 3225 8 3324 10 342...</td>\n",
       "      <td>221</td>\n",
       "      <td>0.482796</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>edf1e6ac00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           rle_mask    z  \\\n",
       "0     575d24d81d                                                NaN  843   \n",
       "1     a266a2a9df                                          5051 5151  794   \n",
       "2     75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468   \n",
       "3     34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727   \n",
       "4     4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797   \n",
       "...          ...                                                ...  ...   \n",
       "3995  9cbd5ddba4                                                NaN  218   \n",
       "3996  caa039b231  2398 7 2499 11 2600 16 2700 22 2801 26 2901 29...  602   \n",
       "3997  1306fcee4c                                                NaN  177   \n",
       "3998  48d81e93d9  2828 1 2927 3 3026 5 3126 6 3225 8 3324 10 342...  221   \n",
       "3999  edf1e6ac00                                                NaN  460   \n",
       "\n",
       "      coverage  coverage_class  \n",
       "0     0.000000               0  \n",
       "1     0.504950               6  \n",
       "2     0.993334              10  \n",
       "3     0.149201               2  \n",
       "4     0.042839               1  \n",
       "...        ...             ...  \n",
       "3995  0.000000               0  \n",
       "3996  0.376924               4  \n",
       "3997  0.000000               0  \n",
       "3998  0.482796               5  \n",
       "3999  0.000000               0  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg16(input_size, decoder_block,\n",
    "               weights='imagenet',\n",
    "               loss_func='binary_crossentropy',\n",
    "               metrics_list=[my_iou_metric],\n",
    "               use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "#     output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        concat1, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-10-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 14, 14, 512)  2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 14, 14, 512)  100352      center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           center_activation[0][0]          \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 14, 14, 256)  1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 14, 14, 256)  50176       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 28, 28, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 28, 28, 128)  100352      decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 56, 56, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 56, 56, 64)   200704      decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 112, 112, 64) 256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 112, 112, 64) 802816      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,552,001\n",
      "Trainable params: 23,549,889\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg16(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 14, 14, 512)  100352      center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 512)  0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 14, 14, 256)  1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 14, 14, 256)  1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 14, 14, 256)  50176       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 14, 14, 256)  0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 14, 14, 512)  1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 14, 14, 512)  100352      center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 14, 14, 512)  0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 512)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           add_1[0][0]                      \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 256)  295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 256)  0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 56, 56, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 112, 112, 64) 0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,029,489\n",
      "Trainable params: 31,024,209\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 92s 6s/step - loss: 1.0852 - my_iou_metric: 0.3063 - val_loss: 7.4613 - val_my_iou_metric: 0.2500\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.25000, saving model to unet_vgg16.h5\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.7872 - my_iou_metric: 0.4875 - val_loss: 1.9983 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.25000\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 1\n",
    "\n",
    "X_tr = X_tr[:16]\n",
    "y_tr = y_tr[:16]\n",
    "X_val = X_val[:4]\n",
    "y_val = y_val[:4]\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 118.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5250 at threshold: 0.760\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.198571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.196938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.198571\n",
       "std     0.204939   0.196938\n",
       "min     0.200000   0.000000\n",
       "25%     0.370000   0.000000\n",
       "50%     0.540000   0.175000\n",
       "75%     0.710000   0.275000\n",
       "max     0.880000   0.525000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b474a6790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
