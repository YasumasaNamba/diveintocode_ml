{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】コードの書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】学習・推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/tgs-salt-identification-challenge/train.csv')\n",
    "test = pd.read_csv('input/tgs-salt-identification-challenge/sample_submission.csv')\n",
    "depth = pd.read_csv('input/tgs-salt-identification-challenge/depths.csv')\n",
    "\n",
    "train_src = 'input/tgs-salt-identification-challenge/train/'\n",
    "\n",
    "# print('train:\\n{}'.format(train.head()))\n",
    "# print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "# print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('input/tgs-salt-identification-challenge/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('input/tgs-salt-identification-challenge/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a48f59810>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg16(input_size, decoder_block,\n",
    "               weights='imagenet',\n",
    "               loss_func='binary_crossentropy',\n",
    "               metrics_list=[my_iou_metric],\n",
    "               use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "#     output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        concat1, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 14, 14, 512)  2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 14, 14, 512)  100352      center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           center_activation[0][0]          \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 14, 14, 256)  1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 14, 14, 256)  50176       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 28, 28, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 28, 28, 128)  100352      decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 56, 56, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 56, 56, 64)   200704      decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 112, 112, 64) 256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 112, 112, 64) 802816      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,552,001\n",
      "Trainable params: 23,549,889\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg16(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 14, 14, 512)  100352      center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 512)  0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 14, 14, 256)  1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 14, 14, 256)  1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 14, 14, 256)  50176       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 14, 14, 256)  0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 14, 14, 512)  1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 14, 14, 512)  100352      center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 14, 14, 512)  0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 512)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           add_1[0][0]                      \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 256)  295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 256)  0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 56, 56, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 112, 112, 64) 0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,029,489\n",
      "Trainable params: 31,024,209\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 103s 6s/step - loss: 1.0522 - my_iou_metric: 0.3563 - val_loss: 4.0471 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.00000, saving model to unet_vgg16.h5\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.7618 - my_iou_metric: 0.4875 - val_loss: 1.2030 - val_my_iou_metric: 0.2000\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.00000 to 0.20000, saving model to unet_vgg16.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 1\n",
    "\n",
    "X_tr = X_tr[:16]\n",
    "y_tr = y_tr[:16]\n",
    "X_val = X_val[:4]\n",
    "y_val = y_val[:4]\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 26%|██▌       | 9/35 [00:00<00:00, 87.74it/s]\u001b[A\n",
      " 57%|█████▋    | 20/35 [00:00<00:00, 92.24it/s]\u001b[A\n",
      "100%|██████████| 35/35 [00:00<00:00, 101.60it/s][A\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5250 at threshold: 0.780\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.237143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.162627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.237143\n",
       "std     0.204939   0.162627\n",
       "min     0.200000   0.000000\n",
       "25%     0.370000   0.150000\n",
       "50%     0.540000   0.250000\n",
       "75%     0.710000   0.250000\n",
       "max     0.880000   0.525000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nambayasumasa/opt/anaconda3/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 16s 0us/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,903,873\n",
      "Trainable params: 42,852,737\n",
      "Non-trainable params: 51,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 14, 14, 512)  100352      center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 512)  0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 14, 14, 256)  1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 14, 14, 256)  1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 14, 14, 256)  50176       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 14, 14, 256)  0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 14, 14, 512)  1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 14, 14, 512)  100352      center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 14, 14, 512)  0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 512)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           add_1[0][0]                      \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 256)  295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 256)  0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 56, 56, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 112, 112, 64) 0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,029,489\n",
      "Trainable params: 31,024,209\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 88s 5s/step - loss: 1.1079 - my_iou_metric: 0.3313 - val_loss: 7.4440 - val_my_iou_metric: 0.2500\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.25000, saving model to unet_vgg16.h5\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.8099 - my_iou_metric: 0.4750 - val_loss: 4.4988 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|████      | 14/35 [00:00<00:00, 133.78it/s]\u001b[A\n",
      "100%|██████████| 35/35 [00:00<00:00, 136.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.2750 at threshold: 0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.115963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.067143\n",
       "std     0.204939   0.115963\n",
       "min     0.200000   0.000000\n",
       "25%     0.370000   0.000000\n",
       "50%     0.540000   0.000000\n",
       "75%     0.710000   0.125000\n",
       "max     0.880000   0.275000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 1\n",
    "\n",
    "X_tr = X_tr[:16]\n",
    "y_tr = y_tr[:16]\n",
    "X_val = X_val[:4]\n",
    "y_val = y_val[:4]\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)\n",
    "\n",
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))\n",
    "\n",
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])\n",
    "\n",
    "df_iou2 = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou2['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou2['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou2.iou[best_index], df_iou2.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b46259790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou', label='unet_vgg16')\n",
    "df_iou2.plot(x='threshold', y='iou', label='unet_resnet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
